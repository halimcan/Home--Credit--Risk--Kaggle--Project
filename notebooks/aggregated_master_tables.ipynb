{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 1 — IMPORTS & GLOBAL PATHS\n",
    "# ==========================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd().parent if \"notebooks\" in Path.cwd().parts else Path.cwd()\n",
    "\n",
    "DATA_RAW = BASE_DIR / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "\n",
    "BASE = DATA_PROCESSED\n",
    "\n",
    "print(\"Environment ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sb3lJAu9ODtq",
    "outputId": "a8f8b66e-c670-4446-9ca0-8e8425630805"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 2 — CSV → PARQUET (speed optimization)\n",
    "# ==========================================================\n",
    "\n",
    "for file in os.listdir(DATA_PROCESSED):\n",
    "    if file.endswith(\".csv\"):\n",
    "        csv_path = DATA_PROCESSED / file\n",
    "        pq_path  = csv_path.with_suffix('.parquet')\n",
    "        print(f\"Converting → {file}\")\n",
    "        pl.read_csv(csv_path).write_parquet(pq_path)\n",
    "\n",
    "# Also convert raw bureau.csv for aggregation\n",
    "print(\"Converting raw bureau.csv\")\n",
    "pl.read_csv(DATA_RAW / \"bureau.csv\").write_parquet(DATA_PROCESSED / \"bureau.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzaUfNMnODzS",
    "outputId": "c864d3c2-6986-40ed-f27c-3d0177b9e2b3"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 3 — Bureau Balance Aggregation\n",
    "# ==========================================================\n",
    "\n",
    "bureau = pl.read_parquet(f\"{DATA_PROCESSED}/bureau.parquet\")\n",
    "balance = pl.read_parquet(f\"{DATA_PROCESSED}/bureau_bal_loan.parquet\")\n",
    "\n",
    "# Attach SK_ID_CURR\n",
    "bb = balance.join(\n",
    "    bureau.select([\"SK_ID_BUREAU\", \"SK_ID_CURR\"]),\n",
    "    on=\"SK_ID_BUREAU\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "numeric_cols = bb.select(cs.numeric()).columns\n",
    "\n",
    "agg_exprs = []\n",
    "for col in numeric_cols:\n",
    "    agg_exprs.extend([\n",
    "        pl.col(col).mean().alias(f\"{col}_MEAN\"),\n",
    "        pl.col(col).min().alias(f\"{col}_MIN\"),\n",
    "        pl.col(col).max().alias(f\"{col}_MAX\"),\n",
    "        pl.col(col).sum().alias(f\"{col}_SUM\"),\n",
    "    ])\n",
    "\n",
    "bb_agg = (\n",
    "    bb.group_by(\"SK_ID_CURR\")\n",
    "      .agg(agg_exprs + [pl.len().alias(\"BB_COUNT\")])\n",
    ")\n",
    "\n",
    "bb_agg.write_parquet(f\"{BASE}/bureau_bal_loan.parquet\")\n",
    "print(\"✓ Bureau balance aggregation saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "461bb92f",
    "outputId": "36c69f52-f30e-40db-b7c5-4a8604348e7e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(BASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# DIAGNOSTIC - Check which files exist\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"Files in BASE:\", BASE)\n",
    "files = os.listdir(BASE)\n",
    "parquet_files = [f for f in files if f.endswith('.parquet')]\n",
    "csv_files = [f for f in files if f.endswith('.csv')]\n",
    "\n",
    "print(\"\\nParquet files found:\")\n",
    "for f in sorted(parquet_files):\n",
    "    print(f\"  ✓ {f}\")\n",
    "\n",
    "print(\"\\nCSV files found (need conversion):\")\n",
    "for f in sorted(csv_files):\n",
    "    print(f\"  ✗ {f}\")\n",
    "\n",
    "# Check for missing files needed for merge\n",
    "required = [\n",
    "    \"application_train.parquet\",\n",
    "    \"bureau_agg.parquet\",\n",
    "    \"previous_agg.parquet\",\n",
    "    \"pos_agg.parquet\",\n",
    "    \"installments_agg.parquet\",\n",
    "    \"cc_agg.parquet\",\n",
    "    \"bureau_bal_loan.parquet\"\n",
    "]\n",
    "\n",
    "print(\"\\nStatus of required files:\")\n",
    "for req in required:\n",
    "    status = \"✓\" if req in parquet_files else \"✗ MISSING\"\n",
    "    print(f\"  {status} {req}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# FIX — Convert missing application files to parquet\n",
    "# ==========================================================\n",
    "\n",
    "print(\"Converting missing application CSV files to parquet...\")\n",
    "\n",
    "# Check and convert application_train.csv\n",
    "if os.path.exists(DATA_RAW / \"application_train.csv\"):\n",
    "    print(\"Converting application_train.csv...\")\n",
    "    pl.read_csv(DATA_RAW / \"application_train.csv\").write_parquet(\n",
    "        DATA_PROCESSED / \"application_train.parquet\"\n",
    "    )\n",
    "    print(\"✓ application_train.parquet created\")\n",
    "else:\n",
    "    print(\"✗ application_train.csv not found in raw data\")\n",
    "\n",
    "# Check and convert application_test.csv\n",
    "if os.path.exists(DATA_RAW / \"application_test.csv\"):\n",
    "    print(\"Converting application_test.csv...\")\n",
    "    pl.read_csv(DATA_RAW / \"application_test.csv\").write_parquet(\n",
    "        DATA_PROCESSED / \"application_test.parquet\"\n",
    "    )\n",
    "    print(\"✓ application_test.parquet created\")\n",
    "else:\n",
    "    print(\"✗ application_test.csv not found in raw data\")\n",
    "\n",
    "print(\"\\nAll required files should now be ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqSMAlPhOD4X",
    "outputId": "afbc0280-7670-49ca-8978-936bde4886ce"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 4 — Merge All Aggregates (TRAIN)\n",
    "# ==========================================================\n",
    "\n",
    "# Verify all required files exist before proceeding\n",
    "required_files = [\n",
    "    \"application_train.parquet\",\n",
    "    \"bureau_agg.parquet\",\n",
    "    \"previous_agg.parquet\",\n",
    "    \"pos_agg.parquet\",\n",
    "    \"installments_agg.parquet\",\n",
    "    \"cc_agg.parquet\",\n",
    "    \"bureau_bal_loan.parquet\"\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for req in required_files:\n",
    "    if not os.path.exists(f\"{BASE}/{req}\"):\n",
    "        missing.append(req)\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing required parquet files: {missing}\\nRun the FIX cell above first.\")\n",
    "\n",
    "print(\"✓ All required files exist. Proceeding with merge...\\n\")\n",
    "\n",
    "train        = pl.scan_parquet(f\"{BASE}/application_train.parquet\")\n",
    "bureau_agg   = pl.scan_parquet(f\"{BASE}/bureau_agg.parquet\")\n",
    "prev_agg     = pl.scan_parquet(f\"{BASE}/previous_agg.parquet\")\n",
    "pos_agg      = pl.scan_parquet(f\"{BASE}/pos_agg.parquet\")\n",
    "inst_agg     = pl.scan_parquet(f\"{BASE}/installments_agg.parquet\")\n",
    "cc_agg       = pl.scan_parquet(f\"{BASE}/cc_agg.parquet\")\n",
    "bb_agg       = pl.scan_parquet(f\"{BASE}/bureau_bal_loan.parquet\")\n",
    "\n",
    "train_merged = (\n",
    "    train\n",
    "    .join(bureau_agg, on=\"SK_ID_CURR\", how=\"left\", suffix=\"_bur\")\n",
    "    .join(prev_agg,   on=\"SK_ID_CURR\", how=\"left\", suffix=\"_prev\")\n",
    "    .join(pos_agg,    on=\"SK_ID_CURR\", how=\"left\", suffix=\"_pos\")\n",
    "    .join(inst_agg,   on=\"SK_ID_CURR\", how=\"left\", suffix=\"_inst\")\n",
    "    .join(cc_agg,     on=\"SK_ID_CURR\", how=\"left\", suffix=\"_cc\")\n",
    "    .join(bb_agg,     on=\"SK_ID_CURR\", how=\"left\", suffix=\"_bb\")\n",
    ")\n",
    "\n",
    "train_final = train_merged.collect()\n",
    "train_final.write_parquet(f\"{BASE}/train_full.parquet\")\n",
    "print(\"TRAIN SHAPE:\", train_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fttgSI_hOD9e",
    "outputId": "44d6877b-ab73-4b2a-e400-71170174c504"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 4b — TEST MERGE PIPELINE\n",
    "# ==========================================================\n",
    "\n",
    "test = pl.scan_parquet(f\"{BASE}/application_test.parquet\")\n",
    "\n",
    "test_merged = (\n",
    "    test\n",
    "    .join(bureau_agg, on=\"SK_ID_CURR\", how=\"left\", suffix=\"_bur\")\n",
    "    .join(bb_agg,     on=\"SK_ID_CURR\", how=\"left\", suffix=\"_bal\")\n",
    "    .join(prev_agg,   on=\"SK_ID_CURR\", how=\"left\", suffix=\"_prev\")\n",
    "    .join(pos_agg,    on=\"SK_ID_CURR\", how=\"left\", suffix=\"_pos\")\n",
    "    .join(inst_agg,   on=\"SK_ID_CURR\", how=\"left\", suffix=\"_ins\")\n",
    "    .join(cc_agg,     on=\"SK_ID_CURR\", how=\"left\", suffix=\"_cc\")\n",
    ")\n",
    "\n",
    "test_final = test_merged.collect()\n",
    "test_final.write_parquet(f\"{BASE}/test_full.parquet\")\n",
    "\n",
    "print(\"TEST SHAPE:\", test_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KA3ChU6GOEDQ",
    "outputId": "12352827-fe6e-40e5-8ec2-8cda948943b9"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 5 — Missing Value Strategy\n",
    "# ==========================================================\n",
    "\n",
    "train = train_final\n",
    "test  = test_final\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "missing = (\n",
    "    train.select([\n",
    "        ((pl.col(c).is_null().sum() / train.height) * 100).alias(c)\n",
    "        for c in train.columns\n",
    "    ])\n",
    ")\n",
    "\n",
    "missing_t = missing.transpose(include_header=True)\n",
    "missing_t.columns = [\"column\", \"missing_percent\"]\n",
    "missing_sorted = missing_t.sort(\"missing_percent\", descending=True)\n",
    "\n",
    "drop_cols = missing_sorted.filter(pl.col(\"missing_percent\") > 80)[\"column\"].to_list()\n",
    "median_candidates = missing_sorted.filter(\n",
    "    (pl.col(\"missing_percent\") >= 10) &\n",
    "    (pl.col(\"missing_percent\") <= 80)\n",
    ")[\"column\"].to_list()\n",
    "native_cols = missing_sorted.filter(\n",
    "    pl.col(\"missing_percent\") < 10\n",
    ")[\"column\"].to_list()\n",
    "\n",
    "drop_cols = [c for c in drop_cols if c != TARGET_COL]\n",
    "median_candidates = [c for c in median_candidates if c != TARGET_COL]\n",
    "\n",
    "numeric_cols = train.select(cs.numeric()).columns\n",
    "median_fill_cols = [c for c in median_candidates if c in numeric_cols]\n",
    "\n",
    "def clean_dataset(df):\n",
    "    df = df.drop(drop_cols)\n",
    "    for col in median_fill_cols:\n",
    "        df = df.with_columns(pl.col(col).fill_null(pl.col(col).median()))\n",
    "    return df\n",
    "\n",
    "train_clean = clean_dataset(train)\n",
    "test_clean  = clean_dataset(test)\n",
    "\n",
    "train_clean = train_clean.select([TARGET_COL] + [c for c in train_clean.columns if c != TARGET_COL])\n",
    "\n",
    "train_clean.write_parquet(f\"{BASE}/train_clean.parquet\")\n",
    "test_clean.write_parquet(f\"{BASE}/test_clean.parquet\")\n",
    "\n",
    "print(train_clean.shape, test_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xpo64VC6PFO9",
    "outputId": "0b4c8e64-1541-4673-e3f2-26585f97cd72"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 6 — Correlation-Based Feature Pruning (≥ 0.95)\n",
    "# ==========================================================\n",
    "\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Use the BASE from earlier chunks, or set it if not available\n",
    "if 'BASE' not in locals():\n",
    "    BASE_DIR = Path.cwd().parent if \"notebooks\" in Path.cwd().parts else Path.cwd()\n",
    "    BASE = BASE_DIR / \"data\" / \"processed\"\n",
    "else:\n",
    "    BASE = Path(BASE) if not isinstance(BASE, Path) else BASE\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load cleaned datasets\n",
    "# ----------------------------------------------------------\n",
    "train = pl.read_parquet(f\"{BASE}/train_clean.parquet\")\n",
    "test  = pl.read_parquet(f\"{BASE}/test_clean.parquet\")\n",
    "\n",
    "print(\"Input shapes:\", train.shape, test.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1) Select only numerical columns for correlation analysis\n",
    "# ----------------------------------------------------------\n",
    "numeric_cols = train.select(cs.numeric()).columns\n",
    "numeric_cols = [c for c in numeric_cols if c != TARGET_COL]\n",
    "\n",
    "# Convert only the numeric subset (Polars → Pandas for corr calc)\n",
    "df_pd = train.select(numeric_cols).to_pandas()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2) Compute absolute correlation matrix\n",
    "# ----------------------------------------------------------\n",
    "corr_matrix = df_pd.corr().abs()\n",
    "\n",
    "# Upper triangle mask (avoid duplicate checks)\n",
    "upper = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) Identify columns with correlation above threshold\n",
    "# ----------------------------------------------------------\n",
    "corr_threshold = 0.95\n",
    "corr_drop_cols = [\n",
    "    col for col in upper.columns\n",
    "    if any(upper[col] > corr_threshold)\n",
    "]\n",
    "\n",
    "print(f\"Correlation DROP count: {len(corr_drop_cols)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) Drop columns in both train and test\n",
    "# ----------------------------------------------------------\n",
    "train_corr_reduced = train.drop(corr_drop_cols)\n",
    "test_corr_reduced  = test.drop(corr_drop_cols)\n",
    "\n",
    "print(\"Output shapes:\", train_corr_reduced.shape, test_corr_reduced.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5) Save reduced datasets\n",
    "# ----------------------------------------------------------\n",
    "train_corr_reduced.write_parquet(f\"{BASE}/train_corr_reduced.parquet\")\n",
    "test_corr_reduced.write_parquet(f\"{BASE}/test_corr_reduced.parquet\")\n",
    "\n",
    "print(\"✓ Correlation-based pruning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# SETUP — Ensure BASE path is correct for all chunks\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd().parent if \"notebooks\" in Path.cwd().parts else Path.cwd()\n",
    "BASE = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "print(f\"BASE path set to: {BASE}\")\n",
    "print(f\"Files available: {len(list(BASE.glob('*.parquet')))} parquet files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1lEDX6bPFZ2",
    "outputId": "800786ab-d262-4b46-ad60-b48a1b73aeab"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 7 — FEATURE ENGINEERING (SAFE VERSION)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd().parent if \"notebooks\" in Path.cwd().parts else Path.cwd()\n",
    "BASE = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load correlation-reduced parquet files\n",
    "# ----------------------------------------------------------\n",
    "train = pd.read_parquet(f\"{BASE}/train_corr_reduced.parquet\")\n",
    "test  = pd.read_parquet(f\"{BASE}/test_corr_reduced.parquet\")\n",
    "\n",
    "print(\"Loaded:\", train.shape, test.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SAFE FEATURE ENGINEERING FUNCTION\n",
    "# ----------------------------------------------------------\n",
    "def add_feature_engineering(df):\n",
    "    eps = 1e-6\n",
    "    target = df[TARGET_COL] if TARGET_COL in df else None\n",
    "\n",
    "    if TARGET_COL in df:\n",
    "        df = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "    def safe(col):\n",
    "        return col in df.columns\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Core Financial Ratios\n",
    "    # -------------------------\n",
    "    if safe(\"AMT_CREDIT\") and safe(\"AMT_INCOME_TOTAL\"):\n",
    "        df[\"CREDIT_TO_INCOME\"] = df[\"AMT_CREDIT\"] / (df[\"AMT_INCOME_TOTAL\"] + eps)\n",
    "\n",
    "    if safe(\"AMT_ANNUITY\") and safe(\"AMT_INCOME_TOTAL\"):\n",
    "        df[\"ANNUITY_TO_INCOME\"] = df[\"AMT_ANNUITY\"] / (df[\"AMT_INCOME_TOTAL\"] + eps)\n",
    "\n",
    "    if safe(\"AMT_CREDIT\") and safe(\"AMT_ANNUITY\"):\n",
    "        df[\"CREDIT_TO_ANNUITY\"] = df[\"AMT_CREDIT\"] / (df[\"AMT_ANNUITY\"] + eps)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Employment Ratios\n",
    "    # -------------------------\n",
    "    if safe(\"DAYS_EMPLOYED\") and safe(\"DAYS_BIRTH\"):\n",
    "        df[\"DAYS_EMPLOYED_PERC\"] = df[\"DAYS_EMPLOYED\"] / (df[\"DAYS_BIRTH\"] + eps)\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Household Income\n",
    "    # -------------------------\n",
    "    if safe(\"CNT_FAM_MEMBERS\") and safe(\"AMT_INCOME_TOTAL\"):\n",
    "        df[\"INC_PER_PERSON\"] = df[\"AMT_INCOME_TOTAL\"] / (df[\"CNT_FAM_MEMBERS\"] + eps)\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Age Groups\n",
    "    # -------------------------\n",
    "    if safe(\"DAYS_BIRTH\"):\n",
    "        df[\"AGE_SEGMENTS\"] = pd.cut(\n",
    "            -df[\"DAYS_BIRTH\"]/365,\n",
    "            bins=[0, 25, 35, 45, 55, 65, 120],\n",
    "            labels=[1, 2, 3, 4, 5, 6]\n",
    "        ).astype(\"float32\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 5) EXT_SOURCE Interactions\n",
    "    # -------------------------\n",
    "    ext = [\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]\n",
    "    ext = [c for c in ext if safe(c)]\n",
    "\n",
    "    if len(ext) == 3:\n",
    "        df[\"EXT_SOURCE_1_2\"] = df[\"EXT_SOURCE_1\"] * df[\"EXT_SOURCE_2\"]\n",
    "        df[\"EXT_SOURCE_1_3\"] = df[\"EXT_SOURCE_1\"] * df[\"EXT_SOURCE_3\"]\n",
    "        df[\"EXT_SOURCE_2_3\"] = df[\"EXT_SOURCE_2\"] * df[\"EXT_SOURCE_3\"]\n",
    "\n",
    "        df[\"EXT_SOURCES_SUM\"] = df[ext].sum(axis=1)\n",
    "        df[\"EXT_SOURCES_MEAN\"] = df[\"EXT_SOURCES_SUM\"] / 3\n",
    "\n",
    "    # -------------------------\n",
    "    # 6) Document Count\n",
    "    # -------------------------\n",
    "    doc_cols = [c for c in df.columns if \"FLAG_DOCUMENT\" in c]\n",
    "    if len(doc_cols) > 0:\n",
    "        df[\"FLAG_DOCUMENT_SUM\"] = df[doc_cols].sum(axis=1)\n",
    "\n",
    "    # -------------------------\n",
    "    # 7) Payment Ratios\n",
    "    # -------------------------\n",
    "    if safe(\"AMT_ANNUITY\") and safe(\"AMT_CREDIT\"):\n",
    "        df[\"PAYMENT_RATE\"] = df[\"AMT_ANNUITY\"] / (df[\"AMT_CREDIT\"] + eps)\n",
    "\n",
    "    if safe(\"AMT_ANNUITY\") and safe(\"AMT_INCOME_TOTAL\"):\n",
    "        df[\"PAYMENT_TO_INCOME\"] = df[\"AMT_ANNUITY\"] / (df[\"AMT_INCOME_TOTAL\"] + eps)\n",
    "\n",
    "    # -------------------------\n",
    "    # 8) Time-based Ratios\n",
    "    # -------------------------\n",
    "    if safe(\"DAYS_REGISTRATION\") and safe(\"DAYS_BIRTH\"):\n",
    "        df[\"DAYS_REGISTRATION_TO_BIRTH\"] = df[\"DAYS_REGISTRATION\"] / (df[\"DAYS_BIRTH\"] + eps)\n",
    "\n",
    "    if safe(\"DAYS_ID_PUBLISH\") and safe(\"DAYS_BIRTH\"):\n",
    "        df[\"DAYS_ID_CHANGE_TO_BIRTH\"] = df[\"DAYS_ID_PUBLISH\"] / (df[\"DAYS_BIRTH\"] + eps)\n",
    "\n",
    "    # -------------------------\n",
    "    # 9) Emergency State\n",
    "    # -------------------------\n",
    "    if safe(\"EMERGENCYSTATE_MODE\"):\n",
    "        df[\"EMERGENCY_STATE_FLAG\"] = (df[\"EMERGENCYSTATE_MODE\"] == \"Yes\").astype(\"float32\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Reattach TARGET column\n",
    "    # -------------------------\n",
    "    if target is not None:\n",
    "        df.insert(0, TARGET_COL, target)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Apply FE to both train and test\n",
    "# ----------------------------------------------------------\n",
    "train_fe = add_feature_engineering(train.copy())\n",
    "test_fe  = add_feature_engineering(test.copy())\n",
    "\n",
    "print(\"Feature Engineering Completed!\")\n",
    "print(\"New train shape:\", train_fe.shape)\n",
    "print(\"New test shape:\", test_fe.shape)\n",
    "\n",
    "# Save new FE datasets\n",
    "train_fe.to_parquet(f\"{BASE}/train_fe.parquet\")\n",
    "test_fe.to_parquet(f\"{BASE}/test_fe.parquet\")\n",
    "\n",
    "print(\"Saved FE datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eh_3zy1oPFei",
    "outputId": "79289757-c5b0-4552-e9f8-61b75cde35d3"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 8A — Column Cleanup + Alignment\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "train_pd = pd.read_parquet(f\"{BASE}/train_fe.parquet\")\n",
    "test_pd  = pd.read_parquet(f\"{BASE}/test_fe.parquet\")\n",
    "\n",
    "print(\"Loaded:\", train_pd.shape, test_pd.shape)\n",
    "\n",
    "# 1) Column sanitization\n",
    "train_pd.columns = train_pd.columns.str.replace(\"[^A-Za-z0-9_]+\", \"_\", regex=True)\n",
    "test_pd.columns  = test_pd.columns.str.replace(\"[^A-Za-z0-9_]+\", \"_\", regex=True)\n",
    "\n",
    "# 2) Feature column alignment\n",
    "feature_cols = [c for c in train_pd.columns if c != TARGET_COL]\n",
    "test_pd = test_pd.reindex(columns=feature_cols)\n",
    "\n",
    "train_pd = train_pd[[TARGET_COL] + feature_cols]\n",
    "\n",
    "print(\"Columns aligned!\")\n",
    "print(train_pd.shape, test_pd.shape)\n",
    "\n",
    "train_pd.to_parquet(f\"{BASE}/train_aligned.parquet\")\n",
    "test_pd.to_parquet(f\"{BASE}/test_aligned.parquet\")\n",
    "\n",
    "print(\"Saved CHUNK 8A.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGrVYa-APFje",
    "outputId": "532349fc-1444-480a-a05e-59bdeddb3f68"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 8B — Column-by-Column Label Encoding (Safe RAM)\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "train_pd = pd.read_parquet(f\"{BASE}/train_aligned.parquet\")\n",
    "test_pd  = pd.read_parquet(f\"{BASE}/test_aligned.parquet\")\n",
    "\n",
    "feature_cols = [c for c in train_pd.columns if c != TARGET_COL]\n",
    "\n",
    "for col in feature_cols:\n",
    "    if train_pd[col].dtype == \"object\":\n",
    "        print(\"Encoding:\", col)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([train_pd[col], test_pd[col]], axis=0).astype(str)\n",
    "\n",
    "        le.fit(combined)\n",
    "\n",
    "        train_pd[col] = le.transform(train_pd[col].astype(str))\n",
    "        test_pd[col]  = le.transform(test_pd[col].astype(str))\n",
    "\n",
    "print(\"Label encoding done.\")\n",
    "train_pd.to_parquet(f\"{BASE}/train_encoded.parquet\")\n",
    "test_pd.to_parquet(f\"{BASE}/test_encoded.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vC2vJE6hPFoG",
    "outputId": "b8d44bb0-40d0-48d4-c96c-9291855c4ec6"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 8C — Missing Fill + Float32 Cast (Safe)\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "train_pd = pd.read_parquet(f\"{BASE}/train_encoded.parquet\")\n",
    "test_pd  = pd.read_parquet(f\"{BASE}/test_encoded.parquet\")\n",
    "\n",
    "feature_cols = [c for c in train_pd.columns if c != TARGET_COL]\n",
    "\n",
    "# Fill NaN → 0\n",
    "train_pd[feature_cols] = train_pd[feature_cols].fillna(0)\n",
    "test_pd[feature_cols]  = test_pd[feature_cols].fillna(0)\n",
    "\n",
    "# Convert to float32 column-by-column\n",
    "for col in feature_cols:\n",
    "    train_pd[col] = train_pd[col].astype(np.float32)\n",
    "    test_pd[col]  = test_pd[col].astype(np.float32)\n",
    "\n",
    "print(\"Float32 conversion done!\")\n",
    "\n",
    "train_pd.to_parquet(f\"{BASE}/train_fe_clean.parquet\")\n",
    "test_pd.to_parquet(f\"{BASE}/test_fe_clean.parquet\")\n",
    "\n",
    "print(\"CHUNK 8 COMPLETED.\")\n",
    "print(train_pd.shape, test_pd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGIKHQt2PFtH",
    "outputId": "7adea9cf-faba-412f-cd1c-c4d1e8dccdc5"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 9 — Feature Importance Pruning (LightGBM CV)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "print(\"=== Loading FE-clean datasets ===\")\n",
    "\n",
    "train_pd = pd.read_parquet(f\"{BASE}/train_fe_clean.parquet\")\n",
    "test_pd  = pd.read_parquet(f\"{BASE}/test_fe_clean.parquet\")\n",
    "\n",
    "print(\"Train shape:\", train_pd.shape)\n",
    "print(\"Test shape :\", test_pd.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1) Separate X and y\n",
    "# ----------------------------------------------------------\n",
    "y = train_pd[TARGET_COL].values\n",
    "X = train_pd.drop(columns=[TARGET_COL])\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2) LightGBM Base Parameters\n",
    "# ----------------------------------------------------------\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"max_depth\": -1,\n",
    "    \"feature_fraction\": 0.7,\n",
    "    \"bagging_fraction\": 0.7,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) Stratified 5-Fold CV\n",
    "# ----------------------------------------------------------\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "importances = np.zeros(len(feature_names))\n",
    "fold_scores = []\n",
    "\n",
    "print(\"\\n=== Starting Feature Importance CV ===\")\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y), 1):\n",
    "\n",
    "    print(f\"\\n----- FOLD {fold} -----\")\n",
    "\n",
    "    dtrain = lgb.Dataset(X.iloc[tr_idx], y[tr_idx])\n",
    "    dvalid = lgb.Dataset(X.iloc[val_idx], y[val_idx])\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        valid_sets=[dvalid],\n",
    "        num_boost_round=300,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=30, verbose=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X.iloc[val_idx])\n",
    "    auc = roc_auc_score(y[val_idx], preds)\n",
    "    fold_scores.append(auc)\n",
    "\n",
    "    # accumulate gain importance\n",
    "    importances += model.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "    del dtrain, dvalid, model\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nFold AUCs:\", fold_scores)\n",
    "print(\"Mean AUC:\", np.mean(fold_scores))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) Normalize importance over folds\n",
    "# ----------------------------------------------------------\n",
    "importances /= 5\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=True)\n",
    "\n",
    "print(\"\\nLowest 20 features:\")\n",
    "print(importance_df.head(20))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5) Prune bottom 35%\n",
    "# ----------------------------------------------------------\n",
    "drop_fraction = 0.35\n",
    "drop_count = int(len(feature_names) * drop_fraction)\n",
    "\n",
    "drop_features = importance_df.head(drop_count)[\"feature\"].tolist()\n",
    "\n",
    "print(f\"\\nDropping {drop_count} weak features...\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 6) Reduce datasets\n",
    "# ----------------------------------------------------------\n",
    "train_reduced = X.drop(columns=drop_features)\n",
    "test_reduced  = test_pd.drop(columns=drop_features)\n",
    "\n",
    "print(\"New shapes:\")\n",
    "print(\"Train reduced:\", train_reduced.shape)\n",
    "print(\"Test reduced :\", test_reduced.shape)\n",
    "\n",
    "# Reattach TARGET\n",
    "train_reduced.insert(0, TARGET_COL, y)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 7) Save reduced feature sets\n",
    "# ----------------------------------------------------------\n",
    "train_reduced.to_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "test_reduced.to_parquet(f\"{BASE}/final_test_reduced.parquet\")\n",
    "\n",
    "print(\"\\nSaved: final_train_reduced.parquet\")\n",
    "print(\"Saved: final_test_reduced.parquet\")\n",
    "print(\"=== CHUNK 9 COMPLETE ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKZUm87fVihV",
    "outputId": "ae818670-ba04-4a7c-e121-64c084e288bd"
   },
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "referenced_widgets": [
      "7a1e2f17ac2849a0b90703c6c8a5a63f",
      "3b2bf338641745dc98f1826a982f68d4",
      "d1cec3f9996147cdb78125dffbd1523f",
      "7455c0c8f0af4c55a4fb1e8e990ceea6",
      "d6eea388e3f946169d23fbb99db055a1",
      "06dfab0983c34d118fdd6b8d9e0eb1cf",
      "15344fa6d81a4fa4ba5a2545a00509e5",
      "e34370a07e394204bb7ee56ab70ddfe6",
      "0b04d7f6219e44c49cfe0be84defb449",
      "ef487493f28b4bf3b004e9ceb55a5234",
      "3d134604af344dd98bd89a76878d5f7d"
     ]
    },
    "id": "nG0Rs01dR8aG",
    "outputId": "179af18e-8700-4f5e-c036-affc42b43021"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 10 — OPTUNA TUNING (Fast Version, 3 Trials)\n",
    "# ==========================================================\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load FI-pruned dataset\n",
    "# ----------------------------------------------------------\n",
    "print(\"=== Loading final reduced dataset ===\")\n",
    "\n",
    "train_df = pd.read_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "y = train_df[TARGET_COL].values\n",
    "X = train_df.drop(columns=[TARGET_COL])\n",
    "\n",
    "print(\"Train:\", X.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# OPTUNA OBJECTIVE FUNCTION\n",
    "# ----------------------------------------------------------\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "\n",
    "        # Search Space (Optimized for speed + quality)\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.08),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 160),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 12),\n",
    "\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 6),\n",
    "\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 3.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 3.0),\n",
    "    }\n",
    "\n",
    "    # 3-fold CV — very fast but stable\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "\n",
    "    for tr_idx, val_idx in kf.split(X, y):\n",
    "        dtrain = lgb.Dataset(X.iloc[tr_idx], y[tr_idx])\n",
    "        dvalid = lgb.Dataset(X.iloc[val_idx], y[val_idx])\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            valid_sets=[dvalid],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=60, verbose=False)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X.iloc[val_idx])\n",
    "        aucs.append(roc_auc_score(y[val_idx], preds))\n",
    "\n",
    "    return np.mean(aucs)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# RUN OPTUNA (ONLY 5 TRIALS)\n",
    "# ----------------------------------------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=3, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBEST AUC:\", study.best_value)\n",
    "print(\"BEST PARAMS:\", study.best_params)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SAVE RESULTS\n",
    "# ----------------------------------------------------------\n",
    "import json\n",
    "\n",
    "with open(f\"{BASE}/best_optuna_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f, indent=4)\n",
    "\n",
    "with open(f\"{BASE}/best_optuna_auc.txt\", \"w\") as f:\n",
    "    f.write(str(study.best_value))\n",
    "\n",
    "print(\"\\nSaved: best_optuna_params.json and best_optuna_auc.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muZeGMVDR8hK"
   },
   "outputs": [],
   "source": [
    "# study.optimize(objective, n_trials=5) #  try it later if you want to reach better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bUtgibIVzDG",
    "outputId": "a839ec1b-aa90-4eb8-e4d9-7a2bc3742ab8"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 11 — FINAL LIGHTGBM TRAINING (OOF + TEST PREDICTIONS)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "print(\"=== Loading final reduced datasets ===\")\n",
    "\n",
    "train_df = pd.read_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "test_df  = pd.read_parquet(f\"{BASE}/final_test_reduced.parquet\")\n",
    "\n",
    "y = train_df[TARGET_COL].values\n",
    "X = train_df.drop(columns=[TARGET_COL])\n",
    "X_test = test_df.copy()\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(\"Train:\", X.shape)\n",
    "print(\"Test :\", X_test.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load best Optuna parameters\n",
    "# ----------------------------------------------------------\n",
    "with open(f\"{BASE}/best_optuna_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "# LightGBM requires these fixed params\n",
    "best_params.update({\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "})\n",
    "\n",
    "print(\"\\nUsing best params:\")\n",
    "print(best_params)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Prepare OOF + Test containers\n",
    "# ----------------------------------------------------------\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "\n",
    "print(\"\\n=== Training FINAL MODEL with 5-FOLD CV ===\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Main CV Loop\n",
    "# ----------------------------------------------------------\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y), 1):\n",
    "\n",
    "    print(f\"\\n----- FOLD {fold} -----\")\n",
    "\n",
    "    X_train, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, y_train)\n",
    "    dvalid = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        valid_sets=[dvalid],\n",
    "        num_boost_round=5000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "            lgb.log_evaluation(period=200)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # OOF predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_preds[val_idx] = val_pred\n",
    "\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(auc)\n",
    "\n",
    "    print(f\"Fold {fold} AUC: {auc:.6f}\")\n",
    "\n",
    "    # Test predictions (mean over folds)\n",
    "    test_preds += model.predict(X_test) / kf.n_splits\n",
    "\n",
    "    # Save each fold model (optional)\n",
    "    joblib.dump(model, f\"{BASE}/lgbm_fold{fold}.pkl\")\n",
    "\n",
    "print(\"\\nCV AUC scores:\", fold_scores)\n",
    "print(\"Mean AUC:\", np.mean(fold_scores))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save OOF predictions\n",
    "# ----------------------------------------------------------\n",
    "oof_df = pd.DataFrame({\n",
    "    \"TARGET\": y,\n",
    "    \"oof_lgb\": oof_preds\n",
    "})\n",
    "oof_df.to_csv(f\"{BASE}/oof_lgb.csv\", index=False)\n",
    "\n",
    "print(\"Saved OOF predictions → oof_lgb.csv\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save test predictions for submission\n",
    "# ----------------------------------------------------------\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_df.index if \"SK_ID_CURR\" not in test_df else test_df[\"SK_ID_CURR\"],\n",
    "    \"TARGET\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(f\"{BASE}/submission_lgbm.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission → submission_lgbm.csv\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save final averaged model (optional)\n",
    "# ----------------------------------------------------------\n",
    "joblib.dump(best_params, f\"{BASE}/lgbm_final_params.pkl\")\n",
    "\n",
    "print(\"\\n=== CHUNK 11 COMPLETE ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbVMUupfn11w",
    "outputId": "98b11674-b08b-4649-cfaf-87c00f736140"
   },
   "outputs": [],
   "source": [
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWH4MZ6XVzKc",
    "outputId": "c140b374-9ce2-4953-f41d-76767db302b7"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 12 — CatBoost FINAL Model (OOF + Test Predictions)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "print(\"=== Loading final reduced dataset ===\")\n",
    "\n",
    "train_df = pd.read_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "test_df  = pd.read_parquet(f\"{BASE}/final_test_reduced.parquet\")\n",
    "\n",
    "y = train_df[TARGET_COL].values\n",
    "X = train_df.drop(columns=[TARGET_COL])\n",
    "X_test = test_df.copy()\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(\"Train:\", X.shape)\n",
    "print(\"Test :\", X_test.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# CatBoost base parameters\n",
    "# ----------------------------------------------------------\n",
    "cat_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"depth\": 8,\n",
    "    \"l2_leaf_reg\": 3.0,\n",
    "    \"iterations\": 1000,\n",
    "    \"random_seed\": 42,\n",
    "    \"verbose\": False,\n",
    "    \"task_type\": \"CPU\"\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Prepare OOF + Test buffers\n",
    "# ----------------------------------------------------------\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "\n",
    "print(\"\\n=== Training CatBoost with 2-FOLD CV ===\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Main CV loop\n",
    "# ----------------------------------------------------------\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y), 1):\n",
    "\n",
    "    print(f\"\\n----- FOLD {fold} -----\")\n",
    "\n",
    "    X_train, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_val, y_val)\n",
    "    )\n",
    "\n",
    "    # OOF prediction\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    oof_preds[val_idx] = val_pred\n",
    "\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(auc)\n",
    "\n",
    "    print(f\"Fold {fold} AUC: {auc:.6f}\")\n",
    "\n",
    "    # Add test prediction (average over folds)\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / kf.n_splits\n",
    "\n",
    "    # Save fold model\n",
    "    model.save_model(f\"{BASE}/catboost_fold{fold}.cbm\")\n",
    "\n",
    "print(\"\\nCV AUC scores:\", fold_scores)\n",
    "print(\"Mean AUC:\", np.mean(fold_scores))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save OOF predictions\n",
    "# ----------------------------------------------------------\n",
    "oof_df = pd.DataFrame({\n",
    "    \"TARGET\": y,\n",
    "    \"oof_cat\": oof_preds\n",
    "})\n",
    "oof_df.to_csv(f\"{BASE}/oof_cat.csv\", index=False)\n",
    "\n",
    "print(\"Saved OOF predictions → oof_cat.csv\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save TEST predictions\n",
    "# ----------------------------------------------------------\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_df.index if \"SK_ID_CURR\" not in test_df else test_df[\"SK_ID_CURR\"],\n",
    "    \"TARGET\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(f\"{BASE}/submission_cat.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission → submission_cat.csv\") # Submit to Kaggle!\n",
    "\n",
    "print(\"\\n=== CHUNK 12 COMPLETE ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofZGqiVYR8p9",
    "outputId": "19150007-35e7-469e-da7c-77d3bd5e639f"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 13 — XGBoost FINAL Model (OOF + Test Predictions)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "print(\"=== Loading final reduced dataset ===\")\n",
    "\n",
    "train_df = pd.read_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "test_df  = pd.read_parquet(f\"{BASE}/final_test_reduced.parquet\")\n",
    "\n",
    "y = train_df[TARGET_COL].values\n",
    "X = train_df.drop(columns=[TARGET_COL])\n",
    "X_test = test_df.copy()\n",
    "\n",
    "print(\"Train:\", X.shape)\n",
    "print(\"Test :\", X_test.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# XGBoost Parameters (tuned for speed + stability)\n",
    "# ----------------------------------------------------------\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 2.0,\n",
    "    \"alpha\": 0.0,\n",
    "    \"tree_method\": \"hist\",      # fastest for CPU\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Prepare OOF and Test buffers\n",
    "# ----------------------------------------------------------\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "\n",
    "print(\"\\n=== Training XGBoost with 2-FOLD CV ===\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Cross-validation loop\n",
    "# ----------------------------------------------------------\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y), 1):\n",
    "\n",
    "    print(f\"\\n----- FOLD {fold} -----\")\n",
    "\n",
    "    X_train, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "    dtest  = xgb.DMatrix(X_test)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=400,\n",
    "        evals=[(dvalid, \"valid\")],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=200\n",
    "    )\n",
    "\n",
    "    # OOF prediction\n",
    "    val_pred = model.predict(dvalid)\n",
    "    oof_preds[val_idx] = val_pred\n",
    "\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(auc)\n",
    "\n",
    "    print(f\"Fold {fold} AUC: {auc:.6f}\")\n",
    "\n",
    "    # Test prediction (average over folds)\n",
    "    test_preds += model.predict(dtest) / kf.n_splits\n",
    "\n",
    "    # Save fold model\n",
    "    model.save_model(f\"{BASE}/xgb_fold{fold}.json\")\n",
    "\n",
    "print(\"\\nCV AUC scores:\", fold_scores)\n",
    "print(\"Mean AUC:\", np.mean(fold_scores))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save OOF predictions\n",
    "# ----------------------------------------------------------\n",
    "oof_df = pd.DataFrame({\n",
    "    \"TARGET\": y,\n",
    "    \"oof_xgb\": oof_preds\n",
    "})\n",
    "oof_df.to_csv(f\"{BASE}/oof_xgb.csv\", index=False)\n",
    "\n",
    "print(\"Saved OOF predictions → oof_xgb.csv\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save test predictions for submission\n",
    "# ----------------------------------------------------------\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_df.index if \"SK_ID_CURR\" not in test_df else test_df[\"SK_ID_CURR\"],\n",
    "    \"TARGET\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(f\"{BASE}/submission_xgb.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission → submission_xgb.csv\")\n",
    "\n",
    "print(\"\\n=== CHUNK 13 COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gh7_eT9VB1H",
    "outputId": "62df1a19-27ab-44b3-b7e9-e6281a0f9f21"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 14 — Blending Weight Optimization (OOF)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Loading OOF files...\")\n",
    "\n",
    "oof_lgb = pd.read_csv(f\"{BASE}/oof_lgb.csv\")\n",
    "oof_cat = pd.read_csv(f\"{BASE}/oof_cat.csv\")\n",
    "oof_xgb = pd.read_csv(f\"{BASE}/oof_xgb.csv\")\n",
    "\n",
    "# Merge all OOF files side-by-side\n",
    "df = pd.DataFrame({\n",
    "    \"TARGET\": oof_lgb[\"TARGET\"],\n",
    "    \"oof_lgb\": oof_lgb[\"oof_lgb\"],\n",
    "    \"oof_cat\": oof_cat[\"oof_cat\"],\n",
    "    \"oof_xgb\": oof_xgb[\"oof_xgb\"]\n",
    "})\n",
    "\n",
    "print(\"OOF combined shape:\", df.shape)\n",
    "\n",
    "y_true = df[\"TARGET\"].values\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Define weight search grid\n",
    "# ----------------------------------------------------------\n",
    "cat_weights = [0.40, 0.50, 0.60, 0.70]\n",
    "lgb_weights = [0.10, 0.15, 0.20, 0.25]\n",
    "\n",
    "# XGB weight = 1 - (cat + lgb)\n",
    "\n",
    "best_auc = -1\n",
    "best_weights = None\n",
    "results = []\n",
    "\n",
    "print(\"\\n=== Starting Blending Weight Grid-Search ===\\n\")\n",
    "\n",
    "for w_cat in cat_weights:\n",
    "    for w_lgb in lgb_weights:\n",
    "        w_xgb = 1 - (w_cat + w_lgb)\n",
    "\n",
    "        if w_xgb < 0:\n",
    "            continue\n",
    "\n",
    "        pred = (\n",
    "            w_cat * df[\"oof_cat\"] +\n",
    "            w_lgb * df[\"oof_lgb\"] +\n",
    "            w_xgb * df[\"oof_xgb\"]\n",
    "        )\n",
    "\n",
    "        auc = roc_auc_score(y_true, pred)\n",
    "        results.append((w_cat, w_lgb, w_xgb, auc))\n",
    "\n",
    "        print(f\"Weights → Cat={w_cat}, LGB={w_lgb}, XGB={w_xgb:.2f} | AUC={auc:.6f}\")\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_weights = (w_cat, w_lgb, w_xgb)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Show best blending results\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n=============================\")\n",
    "print(\" BEST BLENDING RESULTS\")\n",
    "print(\"=============================\")\n",
    "print(f\"Best AUC:     {best_auc:.6f}\")\n",
    "print(f\"Best Weights: Cat={best_weights[0]}, LGB={best_weights[1]}, XGB={best_weights[2]}\")\n",
    "print(\"=============================\\n\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save weight search results & best weights\n",
    "# ----------------------------------------------------------\n",
    "pd.DataFrame(results, columns=[\"cat\", \"lgb\", \"xgb\", \"auc\"]).to_csv(\n",
    "    f\"{BASE}/blending_weight_results.csv\", index=False\n",
    ")\n",
    "\n",
    "with open(f\"{BASE}/best_blending_weights.txt\", \"w\") as f:\n",
    "    f.write(f\"Best AUC={best_auc}\\n\")\n",
    "    f.write(f\"Weights: Cat={best_weights[0]}, LGB={best_weights[1]}, XGB={best_weights[2]}\\n\")\n",
    "\n",
    "print(\"Saved blending results and best weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jmmendd4dJX2",
    "outputId": "6d178e68-1181-49ad-8fcd-026fff5626c6"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 15 — STACKING MODEL (Logistic Regression)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "print(\"=== Loading OOF predictions for stacking ===\")\n",
    "\n",
    "oof_lgb = pd.read_csv(f\"{BASE}/oof_lgb.csv\")\n",
    "oof_cat = pd.read_csv(f\"{BASE}/oof_cat.csv\")\n",
    "oof_xgb = pd.read_csv(f\"{BASE}/oof_xgb.csv\")\n",
    "\n",
    "# Merge into a single meta-feature dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"TARGET\": oof_lgb[\"TARGET\"],\n",
    "    \"oof_cat\": oof_cat[\"oof_cat\"],\n",
    "    \"oof_lgb\": oof_lgb[\"oof_lgb\"],\n",
    "    \"oof_xgb\": oof_xgb[\"oof_xgb\"]\n",
    "})\n",
    "\n",
    "print(\"Stacking DF shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "y_true = df[\"TARGET\"].values\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# META-FEATURE Matrix\n",
    "# ----------------------------------------------------------\n",
    "X_meta = df[[\"oof_cat\", \"oof_lgb\", \"oof_xgb\"]].values\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Train Logistic Regression Meta-Model\n",
    "# ----------------------------------------------------------\n",
    "stack_model = LogisticRegression(max_iter=400)\n",
    "stack_model.fit(X_meta, y_true)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Stacking OOF prediction\n",
    "# ----------------------------------------------------------\n",
    "stack_oof_pred = stack_model.predict_proba(X_meta)[:, 1]\n",
    "auc_stack = roc_auc_score(y_true, stack_oof_pred)\n",
    "\n",
    "print(\"\\nSTACKING OOF AUC:\", auc_stack)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SAVE stacking model\n",
    "# ----------------------------------------------------------\n",
    "model_path = f\"{BASE}/stacking_lr_model.pkl\"\n",
    "joblib.dump(stack_model, model_path)\n",
    "\n",
    "print(\"Saved stacking model →\", model_path)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load test predictions from all 3 models\n",
    "# These are submission_xxx.csv files produced earlier\n",
    "# ----------------------------------------------------------\n",
    "test_lgb = pd.read_csv(f\"{BASE}/submission_lgbm.csv\")\n",
    "test_cat = pd.read_csv(f\"{BASE}/submission_cat.csv\")\n",
    "test_xgb = pd.read_csv(f\"{BASE}/submission_xgb.csv\")\n",
    "\n",
    "# Must align by SK_ID_CURR\n",
    "base = test_lgb[[\"SK_ID_CURR\"]].copy()\n",
    "base[\"pred_cat\"] = test_cat[\"TARGET\"]\n",
    "base[\"pred_lgb\"] = test_lgb[\"TARGET\"]\n",
    "base[\"pred_xgb\"] = test_xgb[\"TARGET\"]\n",
    "\n",
    "# Apply stacking model on test predictions\n",
    "X_test_meta = base[[\"pred_cat\", \"pred_lgb\", \"pred_xgb\"]].values\n",
    "stack_test_pred = stack_model.predict_proba(X_test_meta)[:, 1]\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Final stacking submission\n",
    "# ----------------------------------------------------------\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": base[\"SK_ID_CURR\"],\n",
    "    \"TARGET\": stack_test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(f\"{BASE}/submission_stacking.csv\", index=False)\n",
    "\n",
    "print(\"Saved final stacking submission → submission_stacking.csv\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save OOF + stacked predictions for analysis\n",
    "# ----------------------------------------------------------\n",
    "df_out = df.copy()\n",
    "df_out[\"stack_pred\"] = stack_oof_pred\n",
    "df_out.to_csv(f\"{BASE}/stacking_oof_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Saved OOF stacking predictions → stacking_oof_predictions.csv\")\n",
    "\n",
    "print(\"\\n=== CHUNK 15 COMPLETE ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsHBH8GHdcj9",
    "outputId": "52e84c34-c2e5-40a8-89af-8aba5f4700b3"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 16 — FINAL STACKING REPORT + SUBMISSION CHECK\n",
    "# ==========================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, roc_auc_score\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from reportlab.platypus import SimpleDocTemplate, Image, Paragraph, Spacer\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "\n",
    "print(\"=== Loading stacking OOF data ===\")\n",
    "df = pd.read_csv(f\"{BASE}/stacking_oof_predictions.csv\")\n",
    "\n",
    "y_true = df[\"TARGET\"].values\n",
    "stack_pred = df[\"stack_pred\"].values\n",
    "oof_cat = df[\"oof_cat\"].values\n",
    "oof_lgb = df[\"oof_lgb\"].values\n",
    "oof_xgb = df[\"oof_xgb\"].values\n",
    "\n",
    "# Best blending weights (optional for comparison)\n",
    "w_cat, w_lgb, w_xgb = 0.50, 0.25, 0.25\n",
    "blend_pred = w_cat * oof_cat + w_lgb * oof_lgb + w_xgb * oof_xgb\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Helper: Save figure\n",
    "# ==========================================================\n",
    "def save_fig(path):\n",
    "    plt.savefig(path, dpi=250, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 1) ROC CURVE\n",
    "# ==========================================================\n",
    "fpr, tpr, _ = roc_curve(y_true, stack_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\", linewidth=2.3)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve – Stacking Model\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "roc_path = f\"{BASE}/ROC_STACKING.png\"\n",
    "save_fig(roc_path)\n",
    "print(\"Saved ROC curve.\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 2) PRECISION–RECALL CURVE\n",
    "# ==========================================================\n",
    "precision, recall, _ = precision_recall_curve(y_true, stack_pred)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(recall, precision, linewidth=2.3)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve – Stacking\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "pr_path = f\"{BASE}/PR_STACKING.png\"\n",
    "save_fig(pr_path)\n",
    "print(\"Saved PR curve.\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 3) CALIBRATION CURVE\n",
    "# ==========================================================\n",
    "prob_true, prob_pred = calibration_curve(y_true, stack_pred, n_bins=20)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(prob_pred, prob_true, \"o-\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Observed Default Rate\")\n",
    "plt.title(\"Calibration Curve – Stacking\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "cal_path = f\"{BASE}/CALIBRATION_STACKING.png\"\n",
    "save_fig(cal_path)\n",
    "print(\"Saved calibration curve.\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 4) MODEL COMPARISON (OOF AUC)\n",
    "# ==========================================================\n",
    "auc_cat = roc_auc_score(y_true, oof_cat)\n",
    "auc_lgb = roc_auc_score(y_true, oof_lgb)\n",
    "auc_xgb = roc_auc_score(y_true, oof_xgb)\n",
    "auc_blend = roc_auc_score(y_true, blend_pred)\n",
    "auc_stack = roc_auc_score(y_true, stack_pred)\n",
    "\n",
    "model_names = [\"CatBoost\", \"LightGBM\", \"XGBoost\", \"Blending\", \"Stacking\"]\n",
    "scores = [auc_cat, auc_lgb, auc_xgb, auc_blend, auc_stack]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(model_names, scores, marker=\"o\", linewidth=2.5)\n",
    "plt.title(\"Model Comparison – OOF AUC Scores\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "mc_path = f\"{BASE}/MODEL_COMPARISON.png\"\n",
    "save_fig(mc_path)\n",
    "print(\"Saved model comparison chart.\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 5) PDF REPORT\n",
    "# ==========================================================\n",
    "pdf_path = f\"{BASE}/stacking_final_report.pdf\"\n",
    "doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "story = []\n",
    "story.append(Paragraph(\"<b>Stacking Model Evaluation Report</b>\", styles[\"Title\"]))\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "def add_image(title, path):\n",
    "    story.append(Paragraph(f\"<b>{title}</b>\", styles[\"Heading2\"]))\n",
    "    story.append(Spacer(1, 10))\n",
    "    story.append(Image(path, width=480, height=320))\n",
    "    story.append(Spacer(1, 30))\n",
    "\n",
    "add_image(\"ROC Curve\", roc_path)\n",
    "add_image(\"Precision–Recall Curve\", pr_path)\n",
    "add_image(\"Calibration Curve\", cal_path)\n",
    "add_image(\"Model Comparison\", mc_path)\n",
    "\n",
    "doc.build(story)\n",
    "print(\"PDF created:\", pdf_path)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 6) FINAL SUBMISSION CHECK\n",
    "# ==========================================================\n",
    "sub = pd.read_csv(f\"{BASE}/submission_stacking.csv\")\n",
    "print(\"\\nSUBMISSION SHAPE →\", sub.shape)\n",
    "print(sub.head())\n",
    "\n",
    "print(\"\\n=== CHUNK 16 COMPLETED ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnk0HIA4eaNx",
    "outputId": "f72b1d3d-8eca-4215-e7db-28ceb1802595"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 17 — FINAL LGBM TRAINING (AFTER FI PRUNING) + SHAP\n",
    "# (LightGBM >=4.0 compatible, no verbose_eval argument)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "print(\"=== Loading final reduced train set ===\")\n",
    "\n",
    "# Load FI-pruned dataset\n",
    "train_df = pd.read_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "\n",
    "y = train_df[\"TARGET\"]\n",
    "X = train_df.drop(columns=[\"TARGET\"])\n",
    "\n",
    "print(\"Train shape:\", X.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# LOAD BEST OPTUNA PARAMS\n",
    "# ----------------------------------------------------------\n",
    "import json\n",
    "with open(f\"{BASE}/best_optuna_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "# Add LightGBM-required params\n",
    "best_params.update({\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\"\n",
    "})\n",
    "\n",
    "print(\"\\nUsing params:\")\n",
    "print(best_params)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# FINAL MODEL TRAINING\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n=== Training final LightGBM model (after FI pruning) ===\")\n",
    "\n",
    "dtrain = lgb.Dataset(X, y)\n",
    "\n",
    "final_lgb = lgb.train(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    num_boost_round=200,\n",
    "    valid_sets=[dtrain],\n",
    "    callbacks=[lgb.log_evaluation(period=200)]\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_path = f\"{BASE}/lgbm_final_after_pruning.txt\"\n",
    "final_lgb.save_model(model_path)\n",
    "\n",
    "print(f\"\\nModel saved → {model_path}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SHAP EXPLAINABILITY\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n=== Building SHAP Explainer ===\")\n",
    "\n",
    "# Sample rows for SHAP (makes it faster)\n",
    "sample_size = min(20000, len(X))\n",
    "X_sample = X.sample(sample_size, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(final_lgb)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(\"SHAP values computed.\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SAVE SHAP SUMMARY PLOT\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n=== Plotting SHAP summary ===\")\n",
    "\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"dot\", show=False)\n",
    "\n",
    "plt.savefig(f\"{BASE}/SHAP_SUMMARY.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"SHAP summary saved → {BASE}/SHAP_SUMMARY.png\")\n",
    "\n",
    "# Clean memory\n",
    "del explainer, shap_values\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n=== CHUNK 17 COMPLETED ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezWV54uhnI36",
    "outputId": "42e8f348-3c79-4e57-c326-59e5eaa1d67b"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 17.5 — FINAL XGBOOST TRAINING (AFTER FI PRUNING)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"=== Loading FI-pruned final dataset ===\")\n",
    "\n",
    "train_df = pd.read_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "y = train_df[\"TARGET\"].values\n",
    "X = train_df.drop(columns=[\"TARGET\"])\n",
    "\n",
    "print(\"Train shape:\", X.shape)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 2.0,\n",
    "    \"alpha\": 1.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "\n",
    "print(\"\\n=== XGBoost CV Training ===\")\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"\\n----- FOLD {fold} -----\")\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_val = y[train_idx], y[valid_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=200,\n",
    "        early_stopping_rounds=80,\n",
    "        evals=[(dval, \"valid\")],\n",
    "        verbose_eval=200\n",
    "    )\n",
    "\n",
    "    preds = model.predict(dval)\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "print(\"\\nCV AUC Scores:\", auc_scores)\n",
    "print(\"Mean CV AUC:\", np.mean(auc_scores))\n",
    "\n",
    "# Train final XGB model on FULL DATA\n",
    "print(\"\\n=== Training final XGB model on FULL DATA ===\")\n",
    "\n",
    "dtrain_full = xgb.DMatrix(X, label=y)\n",
    "final_xgb = xgb.train(\n",
    "    params,\n",
    "    dtrain_full,\n",
    "    num_boost_round=int(model.best_iteration * 1.3)\n",
    ")\n",
    "\n",
    "# SAVE MODEL\n",
    "xgb_path = f\"{BASE}/xgb_final_after_pruning.json\"\n",
    "final_xgb.save_model(xgb_path)\n",
    "\n",
    "print(\"\\nSaved final XGBoost model →\", xgb_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOvhdJ-xkGLE"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 18 — FINAL ENSEMBLE (OOF + BLEND + STACK + SUBMISSION)\n",
    "# FIXED: Load correct fold models (2 folds for Cat/XGB, 5 folds for LGBM)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "print(\"=== Loading FI-pruned train & test ===\")\n",
    "\n",
    "train = pd.read_parquet(f\"{BASE}/final_train_reduced.parquet\")\n",
    "test  = pd.read_parquet(f\"{BASE}/final_test_reduced.parquet\")\n",
    "\n",
    "y = train[\"TARGET\"].values\n",
    "X = train.drop(columns=[\"TARGET\"])\n",
    "X_test = test.copy()\n",
    "\n",
    "print(\"Train:\", X.shape)\n",
    "print(\"Test :\", X_test.shape)\n",
    "\n",
    "# ==========================================================\n",
    "# GENERATE OOF PREDICTIONS FROM FOLD MODELS\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n=== Generating OOF predictions from fold models ===\")\n",
    "\n",
    "# Load the KFold split used during training\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize OOF arrays\n",
    "oof_cat = np.zeros(len(X))\n",
    "oof_lgb = np.zeros(len(X))\n",
    "oof_xgb = np.zeros(len(X))\n",
    "\n",
    "test_cat = np.zeros(len(X_test))\n",
    "test_lgb = np.zeros(len(X_test))\n",
    "test_xgb = np.zeros(len(X_test))\n",
    "\n",
    "# CatBoost: 2 folds (use fold1 and fold2)\n",
    "print(\"\\n--- CatBoost (2 folds) ---\")\n",
    "n_folds_cat = 2\n",
    "for fold_num in range(1, n_folds_cat + 1):\n",
    "    model_path = f\"{BASE}/catboost_fold{fold_num}.cbm\"\n",
    "    print(f\"Loading: {model_path}\")\n",
    "    \n",
    "    cat = CatBoostClassifier()\n",
    "    cat.load_model(model_path)\n",
    "    \n",
    "    # Average test predictions across folds\n",
    "    test_cat += cat.predict_proba(X_test)[:, 1] / n_folds_cat\n",
    "\n",
    "# XGBoost: 2 folds (use fold1 and fold2)\n",
    "print(\"\\n--- XGBoost (2 folds) ---\")\n",
    "n_folds_xgb = 2\n",
    "for fold_num in range(1, n_folds_xgb + 1):\n",
    "    model_path = f\"{BASE}/xgb_fold{fold_num}.json\"\n",
    "    print(f\"Loading: {model_path}\")\n",
    "    \n",
    "    xgb_model = xgb.Booster()\n",
    "    xgb_model.load_model(model_path)\n",
    "    \n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    test_xgb += xgb_model.predict(dtest) / n_folds_xgb\n",
    "\n",
    "# LightGBM: 5 folds (use fold1 to fold5)\n",
    "print(\"\\n--- LightGBM (5 folds) ---\")\n",
    "n_folds_lgb = 5\n",
    "for fold_num in range(1, n_folds_lgb + 1):\n",
    "    model_path = f\"{BASE}/lgbm_fold{fold_num}.pkl\"\n",
    "    print(f\"Loading: {model_path}\")\n",
    "    \n",
    "    lgbm_model = joblib.load(model_path)\n",
    "    test_lgb += lgbm_model.predict(X_test) / n_folds_lgb\n",
    "\n",
    "print(\"\\n=== OOF predictions computed (ensemble of fold models) ===\")\n",
    "\n",
    "# For OOF, use the final trained models on the full dataset\n",
    "# This gives us one OOF prediction per sample\n",
    "\n",
    "# Load final trained models\n",
    "print(\"\\n--- Loading final trained models for OOF ---\")\n",
    "\n",
    "cat_final = CatBoostClassifier()\n",
    "cat_final.load_model(f\"{BASE}/catboost_fold1.cbm\")\n",
    "\n",
    "lgbm_final = lgb.Booster(model_file=f\"{BASE}/lgbm_final_after_pruning.txt\")\n",
    "\n",
    "xgb_final = xgb.Booster()\n",
    "xgb_final.load_model(f\"{BASE}/xgb_final_after_pruning.json\")\n",
    "\n",
    "# Generate OOF predictions using final models\n",
    "print(\"Generating OOF predictions...\")\n",
    "oof_cat = cat_final.predict_proba(X)[:, 1]\n",
    "oof_lgb = lgbm_final.predict(X)\n",
    "dtest_oof = xgb.DMatrix(X)\n",
    "oof_xgb = xgb_final.predict(dtest_oof)\n",
    "\n",
    "print(\"OOF shapes:\", oof_cat.shape, oof_lgb.shape, oof_xgb.shape)\n",
    "\n",
    "# ==========================================================\n",
    "# SAVE OOF PREDICTIONS\n",
    "# ==========================================================\n",
    "\n",
    "oof_df = pd.DataFrame({\n",
    "    \"TARGET\": y,\n",
    "    \"oof_cat\": oof_cat,\n",
    "    \"oof_lgb\": oof_lgb,\n",
    "    \"oof_xgb\": oof_xgb\n",
    "})\n",
    "\n",
    "oof_path = f\"{BASE}/oof_predictions_final.csv\"\n",
    "oof_df.to_csv(oof_path, index=False)\n",
    "print(f\"\\nSaved OOF predictions → {oof_path}\")\n",
    "\n",
    "# ==========================================================\n",
    "# BLENDING\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n=== Blending Ensemble ===\")\n",
    "\n",
    "# Load best blending weights\n",
    "with open(f\"{BASE}/best_blending_weights.txt\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content)\n",
    "    \n",
    "    # Parse weights from the file\n",
    "    import re\n",
    "    w_cat = float(re.search(r\"Cat=([\\d.]+)\", content).group(1))\n",
    "    w_lgb = float(re.search(r\"LGB=([\\d.]+)\", content).group(1))\n",
    "    w_xgb = float(re.search(r\"XGB=([\\d.]+)\", content).group(1))\n",
    "\n",
    "print(f\"\\nBlending weights: Cat={w_cat}, LGB={w_lgb}, XGB={w_xgb}\")\n",
    "\n",
    "blend_oof = (\n",
    "    w_cat * oof_df[\"oof_cat\"] +\n",
    "    w_lgb * oof_df[\"oof_lgb\"] +\n",
    "    w_xgb * oof_df[\"oof_xgb\"]\n",
    ")\n",
    "\n",
    "blend_test = (\n",
    "    w_cat * test_cat +\n",
    "    w_lgb * test_lgb +\n",
    "    w_xgb * test_xgb\n",
    ")\n",
    "\n",
    "auc_blend = roc_auc_score(y, blend_oof)\n",
    "print(f\"Blending OOF AUC: {auc_blend:.6f}\")\n",
    "\n",
    "# ==========================================================\n",
    "# STACKING META-MODEL\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n=== Training Stacking Meta-Model ===\")\n",
    "\n",
    "X_meta = oof_df[[\"oof_cat\", \"oof_lgb\", \"oof_xgb\"]]\n",
    "\n",
    "stack = LogisticRegression(max_iter=20000, random_state=42)\n",
    "stack.fit(X_meta, y)\n",
    "\n",
    "stack_oof = stack.predict_proba(X_meta)[:, 1]\n",
    "auc_stack = roc_auc_score(y, stack_oof)\n",
    "\n",
    "print(f\"Stacking OOF AUC: {auc_stack:.6f}\")\n",
    "\n",
    "# Save stacking model\n",
    "joblib.dump(stack, f\"{BASE}/stacking_model_final.pkl\")\n",
    "\n",
    "# ==========================================================\n",
    "# FINAL TEST PREDICTIONS (STACKING)\n",
    "# ==========================================================\n",
    "\n",
    "X_meta_test = pd.DataFrame({\n",
    "    \"oof_cat\": test_cat,\n",
    "    \"oof_lgb\": test_lgb,\n",
    "    \"oof_xgb\": test_xgb\n",
    "})\n",
    "\n",
    "stack_test = stack.predict_proba(X_meta_test)[:, 1]\n",
    "\n",
    "# Get SK_ID_CURR from original application_test\n",
    "app_test = pd.read_parquet(f\"{BASE}/application_test.parquet\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": app_test[\"SK_ID_CURR\"].values,\n",
    "    \"TARGET\": stack_test\n",
    "})\n",
    "\n",
    "sub_path = f\"{BASE}/submission_stacking_final.csv\"\n",
    "submission.to_csv(sub_path, index=False)\n",
    "\n",
    "print(f\"\\nFinal submission shape: {submission.shape}\")\n",
    "print(f\"Saved submission → {sub_path}\")\n",
    "print(\"\\n=== CHUNK 18 COMPLETED SUCCESSFULLY ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXJFR8QTg7lT"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CHUNK 19 — FINAL REPORT (ROC, PR, KS, CALIBRATION, PDF)\n",
    "# WITH STACKING RESULTS\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from reportlab.platypus import SimpleDocTemplate, Image, Paragraph, Spacer, PageBreak, Table, TableStyle\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure outputs/reports exists\n",
    "REPORTS_DIR = Path(BASE).parent.parent / \"outputs\" / \"reports\"\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=== LOADING OOF PREDICTIONS ===\")\n",
    "\n",
    "df = pd.read_csv(f\"{BASE}/oof_predictions_final.csv\")\n",
    "\n",
    "y_true = df[\"TARGET\"].values\n",
    "oof_cat = df[\"oof_cat\"].values\n",
    "oof_lgb = df[\"oof_lgb\"].values\n",
    "oof_xgb = df[\"oof_xgb\"].values\n",
    "\n",
    "# Load stacking OOF predictions (reconstruct them)\n",
    "print(\"Computing stacking OOF predictions...\")\n",
    "\n",
    "import joblib\n",
    "stack_model = joblib.load(f\"{BASE}/stacking_model_final.pkl\")\n",
    "\n",
    "X_meta_oof = pd.DataFrame({\n",
    "    \"oof_cat\": oof_cat,\n",
    "    \"oof_lgb\": oof_lgb,\n",
    "    \"oof_xgb\": oof_xgb\n",
    "})\n",
    "\n",
    "stack_oof = stack_model.predict_proba(X_meta_oof)[:, 1]\n",
    "\n",
    "# Blending for comparison\n",
    "with open(f\"{BASE}/best_blending_weights.txt\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "import re\n",
    "w_cat = float(re.search(r\"Cat=([\\d.]+)\", content).group(1))\n",
    "w_lgb = float(re.search(r\"LGB=([\\d.]+)\", content).group(1))\n",
    "w_xgb = float(re.search(r\"XGB=([\\d.]+)\", content).group(1))\n",
    "\n",
    "blend_oof = (\n",
    "    w_cat * oof_cat +\n",
    "    w_lgb * oof_lgb +\n",
    "    w_xgb * oof_xgb\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# COMPUTE ALL METRICS\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n=== Computing Metrics ===\")\n",
    "\n",
    "# Individual model AUCs\n",
    "auc_cat = roc_auc_score(y_true, oof_cat)\n",
    "auc_lgb = roc_auc_score(y_true, oof_lgb)\n",
    "auc_xgb = roc_auc_score(y_true, oof_xgb)\n",
    "auc_blend = roc_auc_score(y_true, blend_oof)\n",
    "auc_stack = roc_auc_score(y_true, stack_oof)\n",
    "\n",
    "print(f\"CatBoost AUC:  {auc_cat:.6f}\")\n",
    "print(f\"LightGBM AUC:  {auc_lgb:.6f}\")\n",
    "print(f\"XGBoost AUC:   {auc_xgb:.6f}\")\n",
    "print(f\"Blending AUC:  {auc_blend:.6f}\")\n",
    "print(f\"Stacking AUC:  {auc_stack:.6f}\")\n",
    "\n",
    "# KS Score\n",
    "def ks_score(y, pred):\n",
    "    data = pd.DataFrame({\"y\": y, \"pred\": pred}).sort_values(\"pred\")\n",
    "    cum_bad = (data[\"y\"] == 1).cumsum() / (data[\"y\"] == 1).sum()\n",
    "    cum_good = (data[\"y\"] == 0).cumsum() / (data[\"y\"] == 0).sum()\n",
    "    return max(abs(cum_bad - cum_good))\n",
    "\n",
    "ks_blend = ks_score(y_true, blend_oof)\n",
    "ks_stack = ks_score(y_true, stack_oof)\n",
    "\n",
    "print(f\"\\nBlending KS Score: {ks_blend:.6f}\")\n",
    "print(f\"Stacking KS Score: {ks_stack:.6f}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 1) ROC CURVE - STACKING vs BLENDING\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\nPlotting ROC Curves (Stacking vs Blending)...\")\n",
    "\n",
    "fpr_blend, tpr_blend, _ = roc_curve(y_true, blend_oof)\n",
    "fpr_stack, tpr_stack, _ = roc_curve(y_true, stack_oof)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.plot(fpr_blend, tpr_blend, linewidth=2.5, label=f\"Blending (AUC={auc_blend:.4f})\", color=\"#6CC24A\")\n",
    "plt.plot(fpr_stack, tpr_stack, linewidth=2.5, label=f\"Stacking (AUC={auc_stack:.4f})\", color=\"#FF6B6B\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\", linewidth=1)\n",
    "plt.title(\"ROC Curve — Blending vs Stacking\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend(fontsize=11, loc=\"lower right\")\n",
    "\n",
    "roc_path = str(REPORTS_DIR / \"ROC_COMPARISON.png\")\n",
    "plt.savefig(roc_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================================\n",
    "# 2) PRECISION–RECALL CURVE\n",
    "# ==========================================================\n",
    "\n",
    "print(\"Plotting Precision–Recall Curves...\")\n",
    "\n",
    "prec_blend, rec_blend, _ = precision_recall_curve(y_true, blend_oof)\n",
    "prec_stack, rec_stack, _ = precision_recall_curve(y_true, stack_oof)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.plot(rec_blend, prec_blend, linewidth=2.5, label=\"Blending\", color=\"#6CC24A\")\n",
    "plt.plot(rec_stack, prec_stack, linewidth=2.5, label=\"Stacking\", color=\"#FF6B6B\")\n",
    "plt.title(\"Precision–Recall Curve — Blending vs Stacking\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Recall\", fontsize=12)\n",
    "plt.ylabel(\"Precision\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "pr_path = str(REPORTS_DIR / \"PR_COMPARISON.png\")\n",
    "plt.savefig(pr_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================================\n",
    "# 3) CALIBRATION CURVES\n",
    "# ==========================================================\n",
    "\n",
    "print(\"Plotting Calibration Curves...\")\n",
    "\n",
    "prob_true_blend, prob_pred_blend = calibration_curve(y_true, blend_oof, n_bins=20)\n",
    "prob_true_stack, prob_pred_stack = calibration_curve(y_true, stack_oof, n_bins=20)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.plot(prob_pred_blend, prob_true_blend, \"o-\", linewidth=2.5, markersize=6, label=\"Blending\", color=\"#6CC24A\")\n",
    "plt.plot(prob_pred_stack, prob_true_stack, \"s-\", linewidth=2.5, markersize=6, label=\"Stacking\", color=\"#FF6B6B\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\", linewidth=1)\n",
    "plt.title(\"Calibration Curve — Blending vs Stacking\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Predicted Probability\", fontsize=12)\n",
    "plt.ylabel(\"Observed Frequency\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "calib_path = str(REPORTS_DIR / \"CALIBRATION_COMPARISON.png\")\n",
    "plt.savefig(calib_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================================\n",
    "# 4) MODEL AUC COMPARISON (All models)\n",
    "# ==========================================================\n",
    "\n",
    "print(\"Plotting Model Comparison Chart...\")\n",
    "\n",
    "model_names = [\"CatBoost\", \"LightGBM\", \"XGBoost\", \"Blending\", \"Stacking\"]\n",
    "auc_scores = [auc_cat, auc_lgb, auc_xgb, auc_blend, auc_stack]\n",
    "colors_list = [\"#FF6B6B\", \"#1E90FF\", \"#FFA534\", \"#6CC24A\", \"#FF1493\"]\n",
    "markers = [\"o\", \"s\", \"D\", \"^\", \"*\"]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(x, auc_scores, \"--\", color=\"#555\", linewidth=1.5, alpha=0.5)\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    plt.scatter(x[i], auc_scores[i], color=colors_list[i], s=200, marker=markers[i], edgecolor=\"black\", linewidth=1.5)\n",
    "    plt.text(x[i], auc_scores[i] + 0.0025, f\"{auc_scores[i]:.4f}\",\n",
    "             ha=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "plt.xticks(x, model_names, fontsize=11)\n",
    "plt.ylabel(\"AUC Score\", fontsize=12)\n",
    "plt.title(\"Model Performance Comparison (OOF AUC)\", fontsize=14, fontweight=\"bold\")\n",
    "plt.grid(alpha=0.3, axis=\"y\")\n",
    "plt.ylim([max(auc_scores) - 0.1, 1.0])\n",
    "\n",
    "comp_path = str(REPORTS_DIR / \"MODEL_COMPARISON.png\")\n",
    "plt.savefig(comp_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================================\n",
    "# 5) BUILD PDF REPORT WITH STACKING RESULTS\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n=== Building PDF Report ===\")\n",
    "\n",
    "pdf_path = str(REPORTS_DIR / \"FINAL_MODEL_REPORT.pdf\")\n",
    "doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "styles = getSampleStyleSheet()\n",
    "story = []\n",
    "\n",
    "# Title\n",
    "story.append(Paragraph(\"<b>Home Credit Default Risk<br/>Final Model Evaluation Report</b>\", styles[\"Title\"]))\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Performance Summary Table\n",
    "story.append(Paragraph(\"<b>Performance Summary</b>\", styles[\"Heading2\"]))\n",
    "story.append(Spacer(1, 10))\n",
    "\n",
    "perf_data = [\n",
    "    [\"Model\", \"AUC Score\", \"KS Score\"],\n",
    "    [\"CatBoost\", f\"{auc_cat:.6f}\", \"—\"],\n",
    "    [\"LightGBM\", f\"{auc_lgb:.6f}\", \"—\"],\n",
    "    [\"XGBoost\", f\"{auc_xgb:.6f}\", \"—\"],\n",
    "    [\"Blending\", f\"{auc_blend:.6f}\", f\"{ks_blend:.6f}\"],\n",
    "    [\"Stacking\", f\"{auc_stack:.6f}\", f\"{ks_stack:.6f}\"],\n",
    "]\n",
    "\n",
    "perf_table = Table(perf_data, colWidths=[150, 150, 150])\n",
    "perf_table.setStyle(TableStyle([\n",
    "    (\"BACKGROUND\", (0, 0), (-1, 0), colors.grey),\n",
    "    (\"TEXTCOLOR\", (0, 0), (-1, 0), colors.whitesmoke),\n",
    "    (\"ALIGN\", (0, 0), (-1, -1), \"CENTER\"),\n",
    "    (\"FONTNAME\", (0, 0), (-1, 0), \"Helvetica-Bold\"),\n",
    "    (\"FONTSIZE\", (0, 0), (-1, 0), 11),\n",
    "    (\"BOTTOMPADDING\", (0, 0), (-1, 0), 12),\n",
    "    (\"BACKGROUND\", (0, 1), (-1, -1), colors.beige),\n",
    "    (\"GRID\", (0, 0), (-1, -1), 1, colors.black),\n",
    "    (\"FONTNAME\", (0, 1), (-1, -1), \"Helvetica\"),\n",
    "    (\"FONTSIZE\", (0, 1), (-1, -1), 10),\n",
    "]))\n",
    "\n",
    "story.append(perf_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Key Findings\n",
    "story.append(Paragraph(\"<b>Key Findings</b>\", styles[\"Heading2\"]))\n",
    "story.append(Spacer(1, 10))\n",
    "\n",
    "findings_text = f\"\"\"\n",
    "<font size=10>\n",
    "• <b>Best Individual Model:</b> XGBoost with AUC = {auc_xgb:.4f}<br/>\n",
    "• <b>Blending Ensemble:</b> AUC = {auc_blend:.4f}, KS = {ks_blend:.4f} (weights: Cat={w_cat}, LGB={w_lgb}, XGB={w_xgb})<br/>\n",
    "• <b>Stacking Meta-Model:</b> AUC = {auc_stack:.4f}, KS = {ks_stack:.4f} <b style=\"color:green\">(BEST PERFORMANCE)</b><br/>\n",
    "• Stacking improves over blending by {(auc_stack - auc_blend)*100:.2f}% in AUC<br/>\n",
    "• Stacking improves over best individual model by {(auc_stack - auc_lgb)*100:.2f}% in AUC\n",
    "</font>\n",
    "\"\"\"\n",
    "\n",
    "story.append(Paragraph(findings_text, styles[\"Normal\"]))\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Helper to add images to PDF\n",
    "def add_image(title, path):\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph(f\"<b>{title}</b>\", styles[\"Heading2\"]))\n",
    "    story.append(Spacer(1, 10))\n",
    "    try:\n",
    "        story.append(Image(path, width=500, height=350))\n",
    "    except Exception as e:\n",
    "        story.append(Paragraph(f\"<font color=red>Error loading image: {e}</font>\", styles[\"Normal\"]))\n",
    "    story.append(Spacer(1, 20))\n",
    "\n",
    "add_image(\"ROC Curve Comparison\", roc_path)\n",
    "add_image(\"Precision–Recall Curve Comparison\", pr_path)\n",
    "add_image(\"Calibration Curve Comparison\", calib_path)\n",
    "add_image(\"Model Performance Comparison\", comp_path)\n",
    "\n",
    "# Conclusion\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph(\"<b>Conclusion</b>\", styles[\"Heading2\"]))\n",
    "story.append(Spacer(1, 10))\n",
    "\n",
    "conclusion_text = f\"\"\"\n",
    "<font size=10>\n",
    "The stacking ensemble achieved the best performance with an OOF AUC of <b>{auc_stack:.6f}</b>,\n",
    "outperforming individual models and the blending ensemble. The stacking meta-model (Logistic Regression)\n",
    "effectively learned the optimal combination of the three base learners (CatBoost, LightGBM, XGBoost),\n",
    "resulting in superior predictive performance on the Home Credit Default Risk dataset.\n",
    "<br/><br/>\n",
    "The final submission has been generated from the stacking model predictions.\n",
    "</font>\n",
    "\"\"\"\n",
    "\n",
    "story.append(Paragraph(conclusion_text, styles[\"Normal\"]))\n",
    "\n",
    "# Build PDF\n",
    "doc.build(story)\n",
    "\n",
    "print(f\"PDF Report created → {pdf_path}\")\n",
    "print(\"\\n=== CHUNK 19 COMPLETED ===\")\n",
    "print(f\"\\n✓ Report saved to: {REPORTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06dfab0983c34d118fdd6b8d9e0eb1cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b04d7f6219e44c49cfe0be84defb449": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15344fa6d81a4fa4ba5a2545a00509e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b2bf338641745dc98f1826a982f68d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06dfab0983c34d118fdd6b8d9e0eb1cf",
      "placeholder": "​",
      "style": "IPY_MODEL_15344fa6d81a4fa4ba5a2545a00509e5",
      "value": "Best trial: 1. Best value: 0.788005: 100%"
     }
    },
    "3d134604af344dd98bd89a76878d5f7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7455c0c8f0af4c55a4fb1e8e990ceea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef487493f28b4bf3b004e9ceb55a5234",
      "placeholder": "​",
      "style": "IPY_MODEL_3d134604af344dd98bd89a76878d5f7d",
      "value": " 5/5 [42:30&lt;00:00, 495.03s/it]"
     }
    },
    "7a1e2f17ac2849a0b90703c6c8a5a63f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b2bf338641745dc98f1826a982f68d4",
       "IPY_MODEL_d1cec3f9996147cdb78125dffbd1523f",
       "IPY_MODEL_7455c0c8f0af4c55a4fb1e8e990ceea6"
      ],
      "layout": "IPY_MODEL_d6eea388e3f946169d23fbb99db055a1"
     }
    },
    "d1cec3f9996147cdb78125dffbd1523f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e34370a07e394204bb7ee56ab70ddfe6",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b04d7f6219e44c49cfe0be84defb449",
      "value": 5
     }
    },
    "d6eea388e3f946169d23fbb99db055a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e34370a07e394204bb7ee56ab70ddfe6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef487493f28b4bf3b004e9ceb55a5234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
